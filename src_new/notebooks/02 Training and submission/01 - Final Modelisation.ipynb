{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals: Training the *Final* Models\n",
    "\n",
    "This notebook trains the model on the full *baseline_dataset* for the final prediction on evaluation data.\n",
    "\n",
    "Here, we train a model designed to generalize across water stations in Brazil and France. However, you are not required to follow this approach and may opt to train separate models for different geographic *regions*.\n",
    "\n",
    "This baseline model training example utilizes all available features, with hyperparameters chosen for quick execution rather than optimization. For hyperparameter tuning and feature selection explorations, refer to the `02_exploration` folder.\n",
    "\n",
    "> **Note:** This notebook requires outputs from the `00 Preprocessing` notebooks.\n",
    "\n",
    "<img src=\"../images/notebook-3.png\" alt=\"Experiment Diagram\" style=\"width:75%; text-align:center;\" />\n",
    "\n",
    "### 1. Data Import and Setup\n",
    "\n",
    "This section imports the necessary libraries, sets up environment paths, and includes custom utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 01:07:25.725976: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-26 01:07:25.741684: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-26 01:07:25.759182: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-26 01:07:25.764428: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-26 01:07:25.777852: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-26 01:07:26.665610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from mapie.regression import MapieQuantileRegressor\n",
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..')))\n",
    "\n",
    "from src_new.utils.model import split_dataset, compare_models_per_station, create_deep_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constants :\n",
    "- **INPUT_DIR**: Directory for input data (same as in \"02 - Feature Engineering\").\n",
    "- **MODEL_DIR**: Directory where trained models are saved.\n",
    "- **DATASET_DIR**: Directory where the Zenodo dataset is unzipped.\n",
    "\n",
    "##### Model Parameters\n",
    "\n",
    "- **SEED**: 42 (for reproducibility)\n",
    "- **NUMBER_OF_WEEK**: 4 (one model is trained per week)\n",
    "\n",
    "##### FINAL_MODELS\n",
    "\n",
    "- **mapie**: Combines LightGBM with MAPIE. **MAPIE** (Model Agnostic Prediction Interval Estimator) computes prediction intervals for any regression model using conformal methods.\n",
    "- **qrf**: Quantile Random Forest (natively produces prediction intervals)\n",
    "- **ebm**: Explainable Boosting Machine is used as a exemple that does not natively implement prediction intervals, but that can be customised to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../../../data/input/\"\n",
    "MODEL_DIR = \"../../../models/\"\n",
    "DATASET_DIR = \"../../../dataset/\"\n",
    "\n",
    "SEED = 40\n",
    "NUMBER_OF_WEEK = 4 # Number of weeks to predict one model is trained per week\n",
    "\n",
    "FINAL_MODELS = [\"qrf\",\n",
    "                # \"mapie\",\n",
    "                #\"ebm\",\n",
    "                #\"deep_ensemble\",\n",
    "                ]\n",
    "mapie_enbpi = {}\n",
    "mapie = {}\n",
    "qrf = {}\n",
    "mapie_aci = {}\n",
    "\n",
    "COLUMNS_TO_DROP = [\"water_flow_week1\", \"water_flow_week2\", \"water_flow_week3\", \"water_flow_week4\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Loading\n",
    "Load in the baseline datasets, create the directory to save models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(f\"{INPUT_DIR}dataset_baseline.csv\")\n",
    "\n",
    "dataset_train = dataset_train.set_index(\"ObsDate\")\n",
    "\n",
    "if not os.path.exists(f\"{MODEL_DIR}final/\"):\n",
    "    os.makedirs(f\"{MODEL_DIR}final/\")\n",
    "\n",
    "X_train = dataset_train.drop(columns=COLUMNS_TO_DROP)\n",
    "y_train = {}\n",
    "for i in range(0, NUMBER_OF_WEEK):\n",
    "    y_train[i] = dataset_train[f\"water_flow_week{i+1}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Models training\n",
    "#### a. LGBM + MAPIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapie Model Training Overview\n",
    "\n",
    "- **Configuration:**  \n",
    "  - Sets `ALPHA` (0.1) as the prediction interval level.\n",
    "  - Defines `TIME_VALIDATION` as a split point for creating a validation set.\n",
    "  - Configures LightGBM parameters (`LGBM_PARAMS`) for quantile regression.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.1\n",
    "TIME_VALIDATION = \"2000-01-01 00:00:00\"\n",
    "\n",
    "LGBM_PARAMS = {\n",
    "    \"max_depth\": 15,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"n_estimators\": 500,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"objective\": \"quantile\",\n",
    "    \"alpha\": ALPHA\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data Preparation:**  \n",
    "  - Splits `dataset_train` into training and validation subsets using `split_dataset`.\n",
    "  - Removes unnecessary columns from both the training and validation datasets.\n",
    "  - Extracts target variables for each week (from `water_flow_week1` to `water_flow_week4`).\n",
    "\n",
    "- **Model Training:**  \n",
    "  For each week:\n",
    "  - Initializes a LightGBM regressor with the specified parameters.\n",
    "  - Wraps it in a `MapieQuantileRegressor` to estimate prediction intervals.\n",
    "  - Trains the model on the training data and calibrates it using the validation data.\n",
    "  - Saves the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if \"mapie\" in FINAL_MODELS: \n",
    "    print(\"Training Mapie\")\n",
    "\n",
    "\n",
    "    train_mapie, val_mapie, val_temporal  = split_dataset(dataset_train, 0.75, TIME_VALIDATION)    \n",
    "\n",
    "    X_train_mapie = train_mapie.drop(columns=COLUMNS_TO_DROP)\n",
    "    X_train_mapie = X_train_mapie.drop(columns=[\"station_code\"])\n",
    "    print(len(X_train_mapie.columns))\n",
    "    y_train_mapie = {}\n",
    "    for i in range(0, NUMBER_OF_WEEK):\n",
    "        y_train_mapie[i] = train_mapie[f\"water_flow_week{i+1}\"]\n",
    "\n",
    "    X_val = val_mapie.drop(columns=COLUMNS_TO_DROP)\n",
    "    X_val = X_val.drop(columns=[\"station_code\"])\n",
    "    y_val = {}\n",
    "    y_val[0] = val_mapie[\"water_flow_week1\"]\n",
    "    for i in range(1, NUMBER_OF_WEEK):\n",
    "        y_val[i] = val_mapie[f\"water_flow_week{i+1}\"]\n",
    "\n",
    "    for i in range(NUMBER_OF_WEEK):\n",
    "        print(f\"Training week {i}\")\n",
    "        # Initialize and train MapieQuantileRegressor\n",
    "        regressor = lgb.LGBMRegressor(**LGBM_PARAMS)\n",
    "        mapie[i] = MapieQuantileRegressor(estimator=regressor, method=\"quantile\", cv=\"split\", alpha=ALPHA)\n",
    "        mapie[i].fit(X_train_mapie, y_train_mapie[i], X_calib=X_val, y_calib=y_val[i])\n",
    "        \n",
    "        # save model with date\n",
    "        time = pd.Timestamp.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "        model_path = f\"{MODEL_DIR}final/mapie_quantile_{time}_week_{i}.pkl\"\n",
    "        joblib.dump(mapie[i], model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training week 0\n",
      "Training week 1\n",
      "Training week 2\n",
      "Training week 3\n"
     ]
    }
   ],
   "source": [
    "X_train_qrf = X_train.drop(columns=[\"station_code\"])\n",
    "\n",
    "if \"qrf\" in FINAL_MODELS:\n",
    "    for i in range(NUMBER_OF_WEEK):\n",
    "        print(f\"Training week {i}\")\n",
    "        # Train RandomForestQuantileRegressor\n",
    "        qrf[i] = RandomForestQuantileRegressor(n_estimators=50, max_depth=7, min_samples_leaf=6, n_jobs=-1)\n",
    "        qrf[i].fit(X_train_qrf, y_train[i])\n",
    "\n",
    "        time = pd.Timestamp.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        model_path = f\"{MODEL_DIR}final/qrf_quantile_{time}_week_{i}.pkl\"\n",
    "        joblib.dump(qrf[i], model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
