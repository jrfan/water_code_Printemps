{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 16:29:09.385571: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-26 16:29:09.527249: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-26 16:29:09.581449: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-26 16:29:09.597298: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-26 16:29:09.697510: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-26 16:29:10.962448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from mapie.regression import MapieQuantileRegressor\n",
    "from quantile_forest import RandomForestQuantileRegressor\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..')))\n",
    "\n",
    "from src_new.utils.model import split_dataset, compare_models_per_station, create_deep_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constants :\n",
    "- **INPUT_DIR**: Directory for input data (same as in \"02 - Feature Engineering\").\n",
    "- **MODEL_DIR**: Directory where trained models are saved.\n",
    "- **DATASET_DIR**: Directory where the Zenodo dataset is unzipped.\n",
    "\n",
    "##### Model Parameters\n",
    "\n",
    "- **SEED**: 42 (for reproducibility)\n",
    "- **NUMBER_OF_WEEK**: 4 (one model is trained per week)\n",
    "\n",
    "##### FINAL_MODELS\n",
    "\n",
    "- **mapie**: Combines LightGBM with MAPIE. **MAPIE** (Model Agnostic Prediction Interval Estimator) computes prediction intervals for any regression model using conformal methods.\n",
    "- **qrf**: Quantile Random Forest (natively produces prediction intervals)\n",
    "- **ebm**: Explainable Boosting Machine is used as a exemple that does not natively implement prediction intervals, but that can be customised to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../../../data/input/\"\n",
    "MODEL_DIR = \"../../../models/\"\n",
    "DATASET_DIR = \"../../../dataset/\"\n",
    "\n",
    "SEED = 40\n",
    "NUMBER_OF_WEEK = 4 # Number of weeks to predict one model is trained per week\n",
    "\n",
    "FINAL_MODELS = [\"qrf\",\n",
    "                # \"mapie\",\n",
    "                #\"ebm\",\n",
    "                #\"deep_ensemble\",\n",
    "                ]\n",
    "mapie_enbpi = {}\n",
    "mapie = {}\n",
    "qrf = {}\n",
    "mapie_aci = {}\n",
    "\n",
    "COLUMNS_TO_DROP = [\"water_flow_week1\", \"water_flow_week2\", \"water_flow_week3\", \"water_flow_week4\"]\n",
    "\n",
    "dataset_train = pd.read_csv(f\"{INPUT_DIR}dataset_baseline.csv\")\n",
    "\n",
    "dataset_train = dataset_train.set_index(\"ObsDate\")\n",
    "\n",
    "if not os.path.exists(f\"{MODEL_DIR}final/\"):\n",
    "    os.makedirs(f\"{MODEL_DIR}final/\")\n",
    "\n",
    "dataset_train_2 = dataset_train[dataset_train.station_code.isin([56659998,56994500]) ]#   & (dataset_train.index>=\"1997-12\")\n",
    "X_train_2 = dataset_train_2.drop(columns=COLUMNS_TO_DROP)\n",
    "y_train_2 = {}\n",
    "for i in range(0, NUMBER_OF_WEEK):\n",
    "    y_train_2[i] = dataset_train_2[f\"water_flow_week{i+1}\"]\n",
    "\n",
    "dataset_train = dataset_train[(~dataset_train.station_code.isin([56659998,56994500]))  & (dataset_train.index<=\"1998-12-31\")\n",
    "] #\n",
    "X_train = dataset_train.drop(columns=COLUMNS_TO_DROP)\n",
    "y_train = {}\n",
    "for i in range(0, NUMBER_OF_WEEK):\n",
    "    y_train[i] = dataset_train[f\"water_flow_week{i+1}\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Loading\n",
    "Load in the baseline datasets, create the directory to save models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training week 0\n",
      "Training week 1\n",
      "Training week 2\n",
      "Training week 3\n"
     ]
    }
   ],
   "source": [
    "X_train_qrf = X_train.drop(columns=[\"station_code\"])\n",
    "\n",
    "if \"qrf\" in FINAL_MODELS:\n",
    "    for i in range(NUMBER_OF_WEEK):\n",
    "        print(f\"Training week {i}\")\n",
    "        # Train RandomForestQuantileRegressor\n",
    "        qrf[i] = RandomForestQuantileRegressor(n_estimators=50, max_depth=7, min_samples_leaf=6, n_jobs=-1, random_state=SEED)\n",
    "        qrf[i].fit(X_train_qrf, y_train[i])\n",
    "\n",
    "        #time = pd.Timestamp.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        #model_path = f\"{MODEL_DIR}final/qrf_quantile_{time}_week_{i}.pkl\"\n",
    "        #joblib.dump(qrf[i], model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jfan/env/venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestQuantileRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/jfan/env/venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestQuantileRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/jfan/env/venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestQuantileRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/jfan/env/venv/lib/python3.10/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestQuantileRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum non conformity score is: 9.7\n"
     ]
    }
   ],
   "source": [
    "conformity_score = []\n",
    "for i in range(4):\n",
    "    y_pis_qrf = qrf[i].predict(X_train_2.drop(columns=[\"station_code\"]), quantiles=[ALPHA/2, 1-ALPHA/2])\n",
    "    conformity_score.append(np.quantile(np.maximum(y_pis_qrf[:, 0] - y_train_2[i], y_train_2[i] - y_pis_qrf[:, 1]), 1 - ALPHA))\n",
    "\n",
    "print(\"maximum non conformity score is: {:.1f}\".format(max(conformity_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
